{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9452a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import os\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import copy\n",
    "import argparse\n",
    "import trimesh\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from modules import utils, volutils\n",
    "from modules.models import INR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7de91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='INCODE')\n",
    "\n",
    "# Shared Parameters\n",
    "parser.add_argument('--input',type=str, default='./incode_data/Shape/occupancies/preprocessed_lucy.npy', help='Input image path')\n",
    "parser.add_argument('--output',type=str, default='./output/', help='Output path')\n",
    "parser.add_argument('--inr_model',type=str, default='incode', help='[gauss, mfn, relu, siren, wire, wire2d, ffn, incode]')\n",
    "parser.add_argument('--lr',type=float, default=1e-4, help='Learning rate')\n",
    "parser.add_argument('--using_schedular', type=bool, default=True, help='Whether to use schedular')\n",
    "parser.add_argument('--scheduler_b', type=float, default=0.2, help='Learning rate scheduler')\n",
    "parser.add_argument('--maxpoints', type=int, default=1e5, help='Batch size')\n",
    "parser.add_argument('--niters', type=int, default=2, help='Number if iterations')\n",
    "parser.add_argument('--steps_til_summary', type=int, default=1, help='Number of steps till summary visualization')\n",
    "parser.add_argument('--res', type=int, default=512, help='resolution (N^3) of the mesh, same for xyz')\n",
    "parser.add_argument('--mcubes_thres', type=float, default=0.5, help='Threshold for marching cubes')\n",
    "\n",
    "\n",
    "# INCODE Parameters\n",
    "parser.add_argument('--a_coef',type=float, default=0.1993, help='a coeficient')\n",
    "parser.add_argument('--b_coef',type=float, default=0.0196, help='b coeficient')\n",
    "parser.add_argument('--c_coef',type=float, default=0.0588, help='c coeficient')\n",
    "parser.add_argument('--d_coef',type=float, default=0.0269, help='d coeficient')\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c268067e",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d16c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading .npy file from the pre-processing code\n",
    "\n",
    "data = np.load(args.input, allow_pickle=True)[()]\n",
    "\n",
    "### Loading input im with the shape of [res, res, res]\n",
    "scale = 1.0\n",
    "im = np.unpackbits(data['im']).reshape(args.res, args.res, args.res)[..., None].astype(np.float32)[...,0]\n",
    "im = ndimage.zoom(im/im.max(), [scale, scale, scale], order=0)\n",
    "\n",
    "hidx, widx, tidx = np.where(im > 0.99)\n",
    "im = im[hidx.min():hidx.max(),\n",
    "        widx.min():widx.max(),\n",
    "        tidx.min():tidx.max()]\n",
    "\n",
    "H, W, T = im.shape\n",
    "\n",
    "\n",
    "### Loading gt_im with the shape of [128, 128, 128] to input into the task-specific model\n",
    "gt_im = np.unpackbits(data['gt_im']).reshape(128, 128, 128)[..., None].astype(np.float32)[...,0]\n",
    "gt_im = ndimage.zoom(gt_im/gt_im.max(), [1.0, 1.0, 1.0], order=0)\n",
    "hidx, widx, tidx = np.where(gt_im > 0.99)\n",
    "gt_im = gt_im[hidx.min():hidx.max(),\n",
    "                widx.min():widx.max(),\n",
    "                tidx.min():tidx.max()]\n",
    "gt_im = gt_im[None, None, ...]\n",
    "gt_im = np.repeat(gt_im, 3, axis=1)\n",
    "gt_im = torch.from_numpy(gt_im).to(device)\n",
    "\n",
    "\n",
    "### loading the initial pose of mesh \n",
    "mesh_whl = data['mesh_whl']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab2563",
   "metadata": {},
   "source": [
    "## Defining Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c717b7",
   "metadata": {},
   "source": [
    "### Defining desired Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cdf32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Encoding\n",
    "pos_encode_freq = {'type':'frequency', 'use_nyquist': True, 'mapping_input': int(max(H, W, T))}\n",
    "\n",
    "# Gaussian Encoding\n",
    "pos_encode_gaus = {'type':'gaussian', 'scale_B': 10, 'mapping_input': 256}\n",
    "\n",
    "# No Encoding\n",
    "pos_encode_no = {'type': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c1145d",
   "metadata": {},
   "source": [
    "### Model Configureations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d602b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Harmonizer Configurations\n",
    "MLP_configs={'task': 'shape',\n",
    "             'model': 'r3d_18',\n",
    "             'truncated_layer':3,\n",
    "             'in_channels': 128,             \n",
    "             'hidden_channels': [64, 32, 4],\n",
    "             'mlp_bias':0.3120,\n",
    "             'activation_layer': nn.SiLU,\n",
    "             'GT': gt_im\n",
    "            }\n",
    "\n",
    "### Model Configurations\n",
    "model = INR(args.inr_model).run(in_features=3,\n",
    "                                out_features=1, \n",
    "                                hidden_features=256,\n",
    "                                hidden_layers=3,\n",
    "                                first_omega_0=30.0,\n",
    "                                hidden_omega_0=30.0,\n",
    "                                pos_encode_configs=pos_encode_no, \n",
    "                                MLP_configs = MLP_configs\n",
    "                               ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db268c3d",
   "metadata": {},
   "source": [
    "## Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f58b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer setup\n",
    "optim = torch.optim.Adam(lr=args.lr, params=model.parameters())\n",
    "scheduler = lr_scheduler.LambdaLR(optim, lambda x: args.scheduler_b ** min(x / args.niters, 1))\n",
    "\n",
    "# Initialize lists for IOU and best loss value as positive infinity\n",
    "iou_values = []\n",
    "best_iou = torch.tensor(float('inf'))\n",
    "\n",
    "# Generate coordinate grid\n",
    "coords = utils.get_coords(H, W, T, dim=3)[None, ...]\n",
    "\n",
    "# Convert input image to a tensor and reshape\n",
    "gt = torch.tensor(im).reshape(H * W * T, 1)[None, ...].to(device)\n",
    "\n",
    "# Initialize a tensor for reconstructed data\n",
    "rec = torch.zeros_like(gt)\n",
    "\n",
    "# Check the args.maxpoints value\n",
    "args.maxpoints = int(min(H*W*T, args.maxpoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a452e7cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for step in tqdm(range(args.niters)):\n",
    "    # Randomize the order of data points for each iteration\n",
    "    indices = torch.randperm(H*W*T)\n",
    "\n",
    "    loss_values = []\n",
    "    # Process data points in batches\n",
    "    for b_idx in range(0, H*W*T, args.maxpoints):\n",
    "        b_indices = indices[b_idx:min(H*W*T, b_idx+args.maxpoints)]\n",
    "        b_coords = coords[:, b_indices, ...].to(device)\n",
    "        b_indices = b_indices.to(device)\n",
    "        \n",
    "        # Calculate model output\n",
    "        if args.inr_model == 'incode':\n",
    "            model_output, coef = model(b_coords)  \n",
    "        else:\n",
    "            model_output = model(b_coords) \n",
    "\n",
    "        # Update the reconstructed data\n",
    "        with torch.no_grad():\n",
    "            rec[:, b_indices, :] = model_output\n",
    "\n",
    "        # Calculate the output loss\n",
    "        output_loss = ((model_output - gt[:, b_indices, :])**2).mean()\n",
    "        \n",
    "        if args.inr_model == 'incode':\n",
    "            # Calculate regularization loss for 'incode' model\n",
    "            a_coef, b_coef, c_coef, d_coef = coef[0]  \n",
    "            reg_loss = args.a_coef * torch.relu(-a_coef) + \\\n",
    "                       args.b_coef * torch.relu(-b_coef) + \\\n",
    "                       args.c_coef * torch.relu(-c_coef) + \\\n",
    "                       args.d_coef * torch.relu(-d_coef)\n",
    "\n",
    "            # Total loss for 'incode' model\n",
    "            loss = output_loss + reg_loss \n",
    "        else: \n",
    "            # Total loss for other models\n",
    "            loss = output_loss\n",
    "        loss_values.append(loss.item())\n",
    "\n",
    "        # Perform backpropagation and update model parameters\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    \n",
    "    # Calculate IOU\n",
    "    with torch.no_grad():\n",
    "        iou = volutils.get_IoU(rec, gt, args.mcubes_thres)\n",
    "        iou_values.append(iou.item())\n",
    "\n",
    "    # Adjust learning rate using a scheduler if applicable\n",
    "    if args.using_schedular:\n",
    "        if args.inr_model == 'incode' and 30 < step:\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            scheduler.step()\n",
    "\n",
    "    # Prepare reconstructed shape for visualization\n",
    "    imrec = rec[0, ...].reshape(H, W, T).detach().cpu().numpy()\n",
    "\n",
    "    # Check if the current iteration's loss is the best so far\n",
    "    if (iou > best_iou) or (step == 0):\n",
    "        best_iou = iou\n",
    "        best_img = copy.deepcopy(imrec)\n",
    "\n",
    "    # Display intermediate results at specified intervals\n",
    "    if step % args.steps_til_summary == 0:\n",
    "        print(\"Epoch: {} | Total Loss: {:.5f} | IoU: {:.4f}\".format(step, \n",
    "                                                                     np.mean(loss_values),\n",
    "                                                                     iou.item()))\n",
    "\n",
    "        \n",
    "# Print maximum PSNR achieved during training\n",
    "print('--------------------')\n",
    "print('Max PSNR:', max(iou_values))\n",
    "print('--------------------')\n",
    "\n",
    "\n",
    "# Marching and saving volumes\n",
    "expname = os.path.splitext(os.path.basename(args.input))[0]\n",
    "os.makedirs(args.output + args.inr_model, exist_ok=True)\n",
    "savename = f'{args.output}/{args.inr_model}/{expname}.dae'\n",
    "volutils.march_and_save(best_img, mesh_whl, args.mcubes_thres, savename, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0942bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marching and saving volumes\n",
    "expname = os.path.splitext(os.path.basename(args.input))[0]\n",
    "os.makedirs(args.output + args.inr_model, exist_ok=True)\n",
    "savename = f'{args.output}/{args.inr_model}/{expname}.dae'\n",
    "volutils.march_and_save(best_img, mesh_whl, args.mcubes_thres, savename, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86e4b9e",
   "metadata": {},
   "source": [
    "# Convergance Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc2a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'font': 'Times New Roman', 'size': 12}\n",
    "\n",
    "plt.figure()\n",
    "axfont = {'family' : 'Times New Roman', 'weight' : 'regular', 'size'   : 10}\n",
    "plt.rc('font', **axfont)\n",
    "\n",
    "plt.plot(np.arange(len(iou_values[:-1])), iou_values[:-1], label = f\"{(args.inr_model).upper()}\")\n",
    "plt.xlabel('# Epochs', fontdict=font)\n",
    "plt.ylabel('IoU', fontdict=font)\n",
    "plt.title('Shape Representation', fontdict={'family': 'Times New Roman', 'size': 12, 'weight': 'bold'})\n",
    "plt.legend()\n",
    "plt.grid(True, color='lightgray')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
