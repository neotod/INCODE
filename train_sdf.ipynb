{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df9452a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import os\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import copy\n",
    "import argparse\n",
    "import trimesh\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from modules import utils, volutils\n",
    "from modules.models import INR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7de91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='INCODE')\n",
    "\n",
    "# Shared Parameters\n",
    "parser.add_argument('--input',type=str, default='./incode_data/Shape/occupancies/preprocessed_lucy.npy', help='Input image path')\n",
    "parser.add_argument('--output',type=str, default='./output/', help='Output path')\n",
    "parser.add_argument('--inr_model',type=str, default='parac', help='[gauss, mfn, relu, siren, wire, wire2d, ffn, incode, parac]')\n",
    "parser.add_argument('--lr',type=float, default=1e-4, help='Learning rate')\n",
    "parser.add_argument('--using_schedular', type=bool, default=True, help='Whether to use schedular')\n",
    "parser.add_argument('--scheduler_b', type=float, default=0.2, help='Learning rate scheduler')\n",
    "parser.add_argument('--maxpoints', type=int, default=1e1, help='Batch size')\n",
    "parser.add_argument('--niters', type=int, default=2, help='Number if iterations')\n",
    "parser.add_argument('--steps_til_summary', type=int, default=1, help='Number of steps till summary visualization')\n",
    "parser.add_argument('--res', type=int, default=512, help='resolution (N^3) of the mesh, same for xyz')\n",
    "parser.add_argument('--mcubes_thres', type=float, default=0.5, help='Threshold for marching cubes')\n",
    "\n",
    "\n",
    "# INCODE Parameters\n",
    "parser.add_argument('--a_coef',type=float, default=0.1993, help='a coeficient')\n",
    "parser.add_argument('--b_coef',type=float, default=0.0196, help='b coeficient')\n",
    "parser.add_argument('--c_coef',type=float, default=0.0588, help='c coeficient')\n",
    "parser.add_argument('--d_coef',type=float, default=0.0269, help='d coeficient')\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c268067e",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d16c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading .npy file from the pre-processing code\n",
    "\n",
    "data = np.load(args.input, allow_pickle=True)[()]\n",
    "\n",
    "### Loading input im with the shape of [res, res, res]\n",
    "scale = 1.0\n",
    "im = np.unpackbits(data['im']).reshape(args.res, args.res, args.res)[..., None].astype(np.float32)[...,0]\n",
    "im = ndimage.zoom(im/im.max(), [scale, scale, scale], order=0)\n",
    "\n",
    "hidx, widx, tidx = np.where(im > 0.99)\n",
    "im = im[hidx.min():hidx.max(),\n",
    "        widx.min():widx.max(),\n",
    "        tidx.min():tidx.max()]\n",
    "\n",
    "H, W, T = im.shape\n",
    "\n",
    "\n",
    "### Loading gt_im with the shape of [128, 128, 128] to input into the task-specific model\n",
    "gt_im = np.unpackbits(data['gt_im']).reshape(128, 128, 128)[..., None].astype(np.float32)[...,0]\n",
    "gt_im = ndimage.zoom(gt_im/gt_im.max(), [1.0, 1.0, 1.0], order=0)\n",
    "hidx, widx, tidx = np.where(gt_im > 0.99)\n",
    "gt_im = gt_im[hidx.min():hidx.max(),\n",
    "                widx.min():widx.max(),\n",
    "                tidx.min():tidx.max()]\n",
    "gt_im = gt_im[None, None, ...]\n",
    "gt_im = np.repeat(gt_im, 3, axis=1)\n",
    "gt_im = torch.from_numpy(gt_im).to(device)\n",
    "\n",
    "\n",
    "### loading the initial pose of mesh \n",
    "mesh_whl = data['mesh_whl']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab2563",
   "metadata": {},
   "source": [
    "## Defining Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c717b7",
   "metadata": {},
   "source": [
    "### Defining desired Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64cdf32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Encoding\n",
    "pos_encode_freq = {'type':'frequency', 'use_nyquist': True, 'mapping_input': int(max(H, W, T))}\n",
    "\n",
    "# Gaussian Encoding\n",
    "pos_encode_gaus = {'type':'gaussian', 'scale_B': 10, 'mapping_input': 256}\n",
    "\n",
    "# No Encoding\n",
    "pos_encode_no = {'type': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c1145d",
   "metadata": {},
   "source": [
    "### Model Configureations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22d602b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Harmonizer Configurations\n",
    "# MLP_configs={'task': 'shape',\n",
    "#              'model': 'r3d_18',\n",
    "#              'truncated_layer':3,\n",
    "#              'in_channels': 128,             \n",
    "#              'hidden_channels': [64, 32, 4],\n",
    "#              'mlp_bias':0.3120,\n",
    "#              'activation_layer': nn.SiLU,\n",
    "#              'GT': gt_im\n",
    "#             }\n",
    "\n",
    "# ### Model Configurations\n",
    "# model = INR(args.inr_model).run(in_features=3,\n",
    "#                                 out_features=1, \n",
    "#                                 hidden_features=256,\n",
    "#                                 hidden_layers=3,\n",
    "#                                 first_omega_0=30.0,\n",
    "#                                 hidden_omega_0=30.0,\n",
    "#                                 pos_encode_configs=pos_encode_no, \n",
    "#                                 MLP_configs = MLP_configs\n",
    "#                                ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c09599e-3102-4d1e-a696-28d0e8b1beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Configurations for parac\n",
    "model = INR(args.inr_model).run(in_features=3,\n",
    "                                out_features=1, \n",
    "                                hidden_features=256,\n",
    "                                hidden_layers=3,\n",
    "                                first_omega_0=30.0,\n",
    "                                hidden_omega_0=30.0\n",
    "                               ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db268c3d",
   "metadata": {},
   "source": [
    "## Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0ccdbb5-ce16-4e45-8d06-9c781193ba6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f58b062",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# # Optimizer setup\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# optim = torch.optim.Adam(lr=args.lr, params=model.parameters())\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# scheduler = lr_scheduler.LambdaLR(optim, lambda x: args.scheduler_b ** min(x / args.niters, 1))\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Generate coordinate grid\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m coords \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Convert input image to a tensor and reshape\u001b[39;00m\n\u001b[1;32m     13\u001b[0m gt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(im)\u001b[38;5;241m.\u001b[39mreshape(H \u001b[38;5;241m*\u001b[39m W \u001b[38;5;241m*\u001b[39m T, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/run/media/neo/joint/compsci/projects/INCODE/modules/utils.py:232\u001b[0m, in \u001b[0;36mget_coords\u001b[0;34m(H, W, T, dim)\u001b[0m\n\u001b[1;32m    230\u001b[0m     coords \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack((X\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), Y\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 232\u001b[0m     X, Y, Z \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeshgrid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     coords \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack((X\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    236\u001b[0m                         Y\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    237\u001b[0m                         Z\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(coords\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\n",
      "File \u001b[0;32m~/.virtualenvs/inr/lib/python3.11/site-packages/numpy/lib/function_base.py:5164\u001b[0m, in \u001b[0;36mmeshgrid\u001b[0;34m(copy, sparse, indexing, *xi)\u001b[0m\n\u001b[1;32m   5161\u001b[0m     output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbroadcast_arrays(\u001b[38;5;241m*\u001b[39moutput, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m-> 5164\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   5166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/.virtualenvs/inr/lib/python3.11/site-packages/numpy/lib/function_base.py:5164\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   5161\u001b[0m     output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbroadcast_arrays(\u001b[38;5;241m*\u001b[39moutput, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m-> 5164\u001b[0m     output \u001b[38;5;241m=\u001b[39m [\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output]\n\u001b[1;32m   5166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Optimizer setup\n",
    "optim = torch.optim.Adam(lr=args.lr, params=model.parameters())\n",
    "scheduler = lr_scheduler.LambdaLR(optim, lambda x: args.scheduler_b ** min(x / args.niters, 1))\n",
    "\n",
    "# Initialize lists for IOU and best loss value as positive infinity\n",
    "iou_values = []\n",
    "best_iou = torch.tensor(float('inf'))\n",
    "\n",
    "# Generate coordinate grid\n",
    "coords = utils.get_coords(H, W, T, dim=3)[None, ...]\n",
    "\n",
    "# Convert input image to a tensor and reshape\n",
    "gt = torch.tensor(im).reshape(H * W * T, 1)[None, ...].to(device)\n",
    "\n",
    "# Initialize a tensor for reconstructed data\n",
    "rec = torch.zeros_like(gt)\n",
    "\n",
    "# Check the args.maxpoints value\n",
    "args.maxpoints = int(min(H*W*T, args.maxpoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a452e7cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for step in tqdm(range(args.niters)):\n",
    "    # Randomize the order of data points for each iteration\n",
    "    indices = torch.randperm(H*W*T)\n",
    "\n",
    "    loss_values = []\n",
    "    # Process data points in batches\n",
    "    for b_idx in range(0, H*W*T, args.maxpoints):\n",
    "        b_indices = indices[b_idx:min(H*W*T, b_idx+args.maxpoints)]\n",
    "        b_coords = coords[:, b_indices, ...].to(device)\n",
    "        b_indices = b_indices.to(device)\n",
    "        \n",
    "        # Calculate model output\n",
    "        if args.inr_model == 'incode':\n",
    "            model_output, coef = model(b_coords)  \n",
    "        else:\n",
    "            model_output = model(b_coords) \n",
    "\n",
    "        # Update the reconstructed data\n",
    "        with torch.no_grad():\n",
    "            rec[:, b_indices, :] = model_output\n",
    "\n",
    "        # Calculate the output loss\n",
    "        output_loss = ((model_output - gt[:, b_indices, :])**2).mean()\n",
    "        \n",
    "        if args.inr_model == 'incode':\n",
    "            # Calculate regularization loss for 'incode' model\n",
    "            a_coef, b_coef, c_coef, d_coef = coef[0]  \n",
    "            reg_loss = args.a_coef * torch.relu(-a_coef) + \\\n",
    "                       args.b_coef * torch.relu(-b_coef) + \\\n",
    "                       args.c_coef * torch.relu(-c_coef) + \\\n",
    "                       args.d_coef * torch.relu(-d_coef)\n",
    "\n",
    "            # Total loss for 'incode' model\n",
    "            loss = output_loss + reg_loss \n",
    "        else: \n",
    "            # Total loss for other models\n",
    "            loss = output_loss\n",
    "        loss_values.append(loss.item())\n",
    "\n",
    "        # Perform backpropagation and update model parameters\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    \n",
    "    # Calculate IOU\n",
    "    with torch.no_grad():\n",
    "        iou = volutils.get_IoU(rec, gt, args.mcubes_thres)\n",
    "        iou_values.append(iou.item())\n",
    "\n",
    "    # Adjust learning rate using a scheduler if applicable\n",
    "    if args.using_schedular:\n",
    "        if args.inr_model == 'incode' and 30 < step:\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            scheduler.step()\n",
    "\n",
    "    # Prepare reconstructed shape for visualization\n",
    "    imrec = rec[0, ...].reshape(H, W, T).detach().cpu().numpy()\n",
    "\n",
    "    # Check if the current iteration's loss is the best so far\n",
    "    if (iou < best_iou) or (step == 0):\n",
    "        best_iou = iou\n",
    "        best_img = copy.deepcopy(imrec)\n",
    "\n",
    "    # Display intermediate results at specified intervals\n",
    "    if step % args.steps_til_summary == 0:\n",
    "        print(\"Epoch: {} | Total Loss: {:.5f} | IoU: {:.4f}\".format(step, \n",
    "                                                                     np.mean(loss_values),\n",
    "                                                                     iou.item()))\n",
    "\n",
    "        \n",
    "# Print maximum PSNR achieved during training\n",
    "print('--------------------')\n",
    "print('Max PSNR:', max(iou_values))\n",
    "print('--------------------')\n",
    "\n",
    "\n",
    "# Marching and saving volumes\n",
    "expname = os.path.splitext(os.path.basename(args.input))[0]\n",
    "os.makedirs(args.output + args.inr_model, exist_ok=True)\n",
    "savename = f'{args.output}/{args.inr_model}/{expname}.dae'\n",
    "volutils.march_and_save(best_img, mesh_whl, args.mcubes_thres, savename, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0942bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marching and saving volumes\n",
    "expname = os.path.splitext(os.path.basename(args.input))[0]\n",
    "os.makedirs(args.output + args.inr_model, exist_ok=True)\n",
    "savename = f'{args.output}/{args.inr_model}/{expname}.dae'\n",
    "volutils.march_and_save(best_img, mesh_whl, args.mcubes_thres, savename, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86e4b9e",
   "metadata": {},
   "source": [
    "# Convergance Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc2a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'font': 'Times New Roman', 'size': 12}\n",
    "\n",
    "plt.figure()\n",
    "axfont = {'family' : 'Times New Roman', 'weight' : 'regular', 'size'   : 10}\n",
    "plt.rc('font', **axfont)\n",
    "\n",
    "plt.plot(np.arange(len(iou_values[:-1])), iou_values[:-1], label = f\"{(args.inr_model).upper()}\")\n",
    "plt.xlabel('# Epochs', fontdict=font)\n",
    "plt.ylabel('IoU', fontdict=font)\n",
    "plt.title('Shape Representation', fontdict={'family': 'Times New Roman', 'size': 12, 'weight': 'bold'})\n",
    "plt.legend()\n",
    "plt.grid(True, color='lightgray')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
